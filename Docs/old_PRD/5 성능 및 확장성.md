# 5. 성능 및 확장성

### 5-1. 트래픽 예측 및 용량 산정

- **예상 사용자 수**:
    - Phase 1 (MVP 출시 후 3개월): `100~500명 (베타 테스터 + 초기 사용자)`
    - Phase 2 (6개월): `1,000~5,000명`
    - Phase 3 (1년): `10,000~50,000명 (적극적 마케팅 시)`
- **동시 접속자 수 (CCU)**:
    - Phase 1: `10~50명 (Peak: 장 마감 직후)`
    - Phase 2: `50~200명`
    - Phase 3: `200~1,000명`
    - **Peak Time**: `평일 09:00~09:30 (장 시작), 15:00~15:30 (장 마감)`
- **API 호출 예측**:
    - 사용자당 평균 호출: `10~20회/일`
    - 실시간 시세 API: `CCU × 2회/분 (장중)`
    - Phase 1 예상 API 호출: `하루 1,000~10,000회`
    - Phase 3 예상 API 호출: `하루 100,000~500,000회`

### 5-2. 응답 시간 요구사항

- **목표 응답 시간** (95 Percentile):
    - **인증 API**:
        - 로그인: `< 2초 (Google OAuth 포함)`
        - 토큰 갱신: `< 500ms`
    - **포트폴리오 API**:
        - 목록 조회: `< 300ms`
        - 상세 조회: `< 500ms`
        - 생성/수정/삭제: `< 500ms`
    - **종목 API**:
        - 검색: `< 1초 (한투 API 호출 포함)`
        - 추가/수정/삭제: `< 300ms`
    - **실시간 시세 API**:
        - 단일 종목: `< 1초 (한투 API 호출 포함)`
        - 여러 종목 (5~10개): `< 2초`
    - **리밸런싱 분석 API**:
        - 계산 및 제안: `< 1초`
- **목표 설정 근거**:
    - 사용자 체감 속도: `< 100ms (Instant), < 1초 (Fast), < 3초 (Acceptable)`
    - 모바일 환경: `네트워크 지연 고려 (4G/5G/WiFi)`

### 5-3. 서버 인프라 구성

- **Phase 1 (MVP) 구성**:
    - **애플리케이션 서버**:
        - 인스턴스: `AWS EC2 t3.small 1대 (2 vCPU, 2GB RAM)`
        - 예상 비용: `$15~20/월`
    - **데이터베이스**:
        - 인스턴스: `AWS RDS MySQL t3.micro 1대 (20GB SSD)`
        - 예상 비용: `$15~20/월`
    - **총 예상 비용**: `$30~50/월 (트래픽 비용 포함)`
- **Phase 2 (확장) 구성**:
    - **애플리케이션 서버**:
        - 인스턴스: `AWS EC2 t3.medium 2대 (2 vCPU, 4GB RAM) + Load Balancer`
        - Auto Scaling: `최소 2대, 최대 5대`
        - 예상 비용: `$80~150/월`
    - **데이터베이스**:
        - 인스턴스: `AWS RDS MySQL t3.small (100GB SSD)`
        - 예상 비용: `$50~80/월`
    - **캐시 서버** (선택):
        - 인스턴스: `AWS ElastiCache Redis t3.micro`
        - 예상 비용: `$15~20/월`
    - **총 예상 비용**: `$150~250/월`
- **Phase 3 (Scale-out) 구성**:
    - Multi-AZ 배포, CDN(CloudFront), 전용 캐시 서버
    - 예상 비용: `$500~1,000/월`

### 5-4. 데이터베이스 최적화

- **인덱스 전략**:
    - **users 테이블**:
        - Primary Key: `id (UUID)`
        - Unique Index: `email, google_id`
    - **portfolios 테이블**:
        - Primary Key: `id (UUID)`
        - Index: `user_id, (user_id, display_order)`
    - **stocks 테이블**:
        - Primary Key: `id (UUID)`
        - Index: `portfolio_id, (portfolio_id, stock_code)`
    - **notifications 테이블**:
        - Primary Key: `id (UUID)`
        - Unique Index: `portfolio_id`
- **쿼리 최적화**:
    - N+1 문제 해결: `JPA Fetch Join 또는 @EntityGraph 사용`
    - 페이지네이션: `Offset 대신 Cursor 기반 (Phase 2)`
    - 대량 데이터 조회: `Batch Size 설정`
- **커넥션 풀 설정**:
    - 초기 크기: `10`
    - 최대 크기: `50`
    - 타임아웃: `30초`

### 5-5. 캐싱 전략

- **애플리케이션 캐싱**:
    - **실시간 시세 데이터** (Phase 1):
        - 캐시 위치: `모바일 앱 메모리`
        - 캐시 유효기간: `30초~1분`
        - 갱신 전략: `Pull to Refresh 또는 자동 갱신`
    - **실시간 시세 데이터** (Phase 2 - Redis):
        - 캐시 Key: `stock:price:{stock_code}`
        - TTL: `30초`
        - 예상 효과: `한투 API 호출 50~70% 감소`
    - **사용자 세션**:
        - 캐시 Key: `user:session:{user_id}`
        - TTL: `Access Token 유효기간 (1시간)`
    - **종목 검색 결과** (Phase 2):
        - 캐시 Key: `stock:search:{keyword}`
        - TTL: `1시간`
- **CDN 활용** (Phase 3):
    - 정적 리소스: `이미지, CSS, JavaScript`
    - API 응답 캐싱: `공개 데이터 (Phase 3)`

### 5-6. API 최적화

- **Rate Limiting**:
    - 전역 설정: `60회/분 per IP`
    - 인증 API: `10회/분 per IP`
    - 실시간 시세 API: `30회/분 per User`
    - 초과 시: `429 Too Many Requests + Retry-After 헤더`
- **요청 최적화**:
    - Batch API: `여러 종목 한 번에 조회 (Phase 2)`
    - Compression: `gzip 압축 사용`
    - Pagination: `기본 20건, 최대 100건`
- **비동기 처리** (Phase 2):
    - 알림 발송: `메시지 큐 (AWS SQS)`
    - 대량 데이터 처리: `백그라운드 Job`

### 5-7. 모바일 앱 성능 최적화

- **초기 로딩 시간 최소화**:
    - Code Splitting: `React Native의 Lazy Loading`
    - 번들 크기 최적화: `불필요한 라이브러리 제거`
    - 목표: `첫 화면 로딩 < 3초 (4G 환경)`
- **메모리 관리**:
    - 이미지 최적화: `WebP 포맷, 크기 제한 (500KB 이하)`
    - 메모리 누수 방지: `useEffect cleanup, 이벤트 리스너 제거`
    - 목표: `메모리 사용량 < 100MB`
- **네트워크 최적화**:
    - 데이터 압축: `gzip 활성화`
    - 요청 병합: `React Query로 중복 요청 방지`
    - Offline 모드: `로컬 캐시 사용`
- **렌더링 성능**:
    - FlatList 최적화: `windowSize, maxToRenderPerBatch 조정`
    - useMemo/useCallback: `불필요한 리렌더링 방지`
    - 목표: `60 FPS 유지, 스크롤 랙 없음`

### 5-8. 모니터링 및 성능 측정

- **모니터링 지표**:
    - **서버 모니터링**:
        - CPU 사용률: `< 70% (Avg)`
        - 메모리 사용률: `< 80% (Avg)`
        - 디스크 I/O: `< 70% (Avg)`
        - API 응답 시간: `P95 < 1초`
    - **데이터베이스 모니터링**:
        - 커넥션 수: `< 40 (Max 50)`
        - 슬로우 쿼리: `> 1초 쿼리 로깅`
        - 데드락: `모니터링 및 알림`
    - **모바일 앱 모니터링**:
        - 크래시율: `< 1%`
        - ANR율 (Android): `< 0.5%`
        - 앱 시작 시간: `P95 < 3초`
- **모니터링 도구**:
    - Phase 1: `AWS CloudWatch (Basic Metrics)`
    - Phase 2: `CloudWatch + Custom Metrics + APM (New Relic/DataDog 검토)`
    - 모바일: `Firebase Crashlytics (Phase 1부터)`
- **성능 테스트**:
    - 부하 테스트: `Phase 1 출시 전 1회, Phase 2마다`
    - 도구: `Apache JMeter 또는 k6`
    - 시나리오: `예상 CCU의 2배 트래픽 시뮬레이션`

### 5-9. 확장성 전략

- **수평 확장 (Scale-out)**:
    - 서버: `AWS Auto Scaling + Load Balancer`
    - 데이터베이스: `Read Replica 추가 (Phase 2)`
    - Stateless 설계: `세션은 Redis에 저장, 서버 간 공유`
- **수직 확장 (Scale-up)**:
    - 서버: `EC2 인스턴스 타입 업그레이드`
    - 데이터베이스: `RDS 인스턴스 타입 업그레이드`
- **마이크로서비스 아키텍처** (Phase 3):
    - 서비스 분리: `인증, 포트폴리오, 시세, 알림 서비스`
    - 이점: `독립적 확장, 장애 격리`
    - 비용: `초기 비용 증가, 복잡도 증가`

### 5-10. 팀 논의 필요 사항

- [ ]  Phase 1 서버 스펙 최종 결정 (t3.small vs t3.micro)
- [ ]  Redis 캐싱 도입 시점 (Phase 1 vs Phase 2)
- [ ]  모니터링 도구 예산 (CloudWatch vs New Relic vs DataDog)
- [ ]  부하 테스트 수행 주체 (팀 내부 vs 외주)
- [ ]  Auto Scaling 임계값 설정 (CPU 70% vs 80%)
- [ ]  예상 트래픽이 초과할 경우 비상 계획